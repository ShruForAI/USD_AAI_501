{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e1697ce-153f-4ff1-a634-0f126f63c9d4",
   "metadata": {},
   "source": [
    "# Fake News Detection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe89458-ca13-4233-b0e0-d668001e1b0f",
   "metadata": {},
   "source": [
    "**Shruthi AK**\n",
    "\n",
    "**12/09/2024**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b1de49-071d-40b1-b6d3-b34b0c941a5e",
   "metadata": {},
   "source": [
    "**Introduction**\n",
    "\n",
    "The proliferation of fake news poses significant challenges to the integrity of information disseminated online. As fake news spreads quickly and influences public opinion, it becomes crucial to develop robust systems to detect and filter out such content. This project aims to create an effective fake news classification system using a combination of machine learning (ML) and deep learning (DL) models. By leveraging both traditional and advanced techniques, we seek to improve the accuracy and reliability of fake news detection.\n",
    "\n",
    "**Dataset**\n",
    "\n",
    "About the Dataset\r\n",
    "This project is based on the dataset comprising true and false news articles with columns for title, text, subject, and date. The dataset includes21,4172 true news articles and23,4813 false news articles. The focus will be on preprocessing this data effectively and implementing the models to achieve the best possible performance in terms of accuracy.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cabe2eba-a46d-443d-bf8c-5da97aa4430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, SpatialDropout1D, Flatten, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a0b89eb-4393-4095-af25-694fb2c339c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\shrut\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shrut\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\shrut\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4cdbbe-d703-48e1-97d6-9cacdadb5b7e",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15a351f1-a932-4cb8-bff7-8247400210f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV files\n",
    "true_news_df = pd.read_csv('True.csv')\n",
    "false_news_df = pd.read_csv('Fake.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657f7954-0cc1-42fb-bc8c-9848b5cdad52",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "677f62d4-8e1f-4f17-8cb4-a23fffa39a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0  As U.S. budget fight looms, Republicans flip t...   \n",
      "1  U.S. military to accept transgender recruits o...   \n",
      "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
      "3  FBI Russia probe helped by Australian diplomat...   \n",
      "4  Trump wants Postal Service to charge 'much mor...   \n",
      "\n",
      "                                                text       subject  \\\n",
      "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
      "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
      "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
      "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
      "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
      "\n",
      "                 date  label  \n",
      "0  December 31, 2017       1  \n",
      "1  December 29, 2017       1  \n",
      "2  December 31, 2017       1  \n",
      "3  December 30, 2017       1  \n",
      "4  December 29, 2017       1  \n"
     ]
    }
   ],
   "source": [
    "# Combine into a single DataFrame with labels\n",
    "true_news_df['label'] = 1\n",
    "false_news_df['label'] = 0\n",
    "\n",
    "# Concatenate DataFrames\n",
    "df = pd.concat([true_news_df, false_news_df], ignore_index=True)\n",
    "\n",
    "# Check the first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57b728c4-35aa-4c8c-83d8-19588cc3d2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44898 entries, 0 to 44897\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   title    44898 non-null  object\n",
      " 1   text     44898 non-null  object\n",
      " 2   subject  44898 non-null  object\n",
      " 3   date     44898 non-null  object\n",
      " 4   label    44898 non-null  int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check the info of the dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4a2540-7aa6-442b-92de-1146df4e9bee",
   "metadata": {},
   "source": [
    "**There are No Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "868b0e74-179d-43ce-aa78-cb9620f9760b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    23481\n",
       "1    21417\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the target variable value counts\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb0a2730-5335-4f4d-96a9-e1d53899fbce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    0.522985\n",
       "1    0.477015\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5e13fe-2213-48f9-b8d3-a00474eae08b",
   "metadata": {},
   "source": [
    "True News: 47.7% of the total dataset\n",
    "\n",
    "Fake News: 52.3% of the total dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb10235f-1a98-407d-b732-5aca24127f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAIhCAYAAAC8IicCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABFBklEQVR4nO3deVgVdf//8deRXYSjgIAULpU7bmG5pWIuaC6V7RRpt9riFql3Zd2l3pWmlVlurYqV3tZdabZIaihpLiF3pLilZakpuSEoKev8/vDr+Xk+oAIhB/P5uK65rs7Me2bec6ThxYc5H2yWZVkCAAAA4FDF1Q0AAAAAlQ0hGQAAADAQkgEAAAADIRkAAAAwEJIBAAAAAyEZAAAAMBCSAQAAAAMhGQAAADAQkgEAAAADIRnAX7Zp0yY98MADqlevnry9vVWtWjVde+21mjJlio4ePerq9iRJCxYs0LRp0y7Ksf/1r3+pdu3acnd3V/Xq1Yts//XXX2Wz2Uq0/Prrrxelx8pm1apVstlsWrVq1Xnr4uPjz/lejRkzpsTnO/NvEB8f/9caL4Wz/90XLlxYZPv48eNls9l0+PDhCusJQMm5u7oBAJe2t99+W0OHDlXDhg31z3/+U02aNFFeXp42btyoN954Q+vWrdOiRYtc3aYWLFigtLQ0xcXFletxP/vsM73wwgt6+umn1atXL3l5eRWpqVWrltatW+e0bujQocrMzNT8+fOL1KKouXPnqlGjRk7rwsLCXNRN6T399NO67bbb5OHh4epWAJQQIRlAma1bt06PPPKIunfvrsWLFzsFxO7du2v06NFKSEhwYYcXX1pamiRp5MiRCg4OLrbGy8tLbdu2dVrn7++v3NzcIutNJ0+elI+PT/k0ewmLiIhQ69atXd1GmfTq1UtLly7VG2+8oREjRri6HQAlxOMWAMps4sSJstlseuutt4odQfX09FS/fv0crwsLCzVlyhQ1atRIXl5eCg4O1v333699+/Y57Ve3bl0NHDiwyPGioqIUFRXleH3mV/b/+c9/9PTTTyssLEz+/v7q1q2bduzY4bTfl19+qd9++83p1/XnU5Je69atq3/961+SpJCQENlsNo0fP/68xz2funXrqk+fPvr000/VqlUreXt7a8KECed9VKC4c+7cuVMxMTEKDg6Wl5eXGjdurJkzZ5aoh5kzZ6pTp04KDg6Wr6+vmjVrpilTpigvL8+pLioqShEREUpOTlbHjh1VtWpVXXXVVXrxxRdVWFjoVLt9+3b17NlTVatWVVBQkB5++GEdP368VO/NuezatUsPPPCA6tevr6pVq+qKK65Q3759tXnz5gvue+jQIT344IMKDw+Xl5eXatasqQ4dOmjFihVOdStWrFDXrl3l7++vqlWrqkOHDvrmm29K3OONN96o6OhoPffccyW67gudb8uWLbLZbPrvf//rWJeSkiKbzaamTZs6Hatfv36KjIx0vE5MTFRUVJQCAwPl4+Oj2rVr67bbbtOff/5Z4usBLheEZABlUlBQoMTEREVGRio8PLxE+zzyyCN64okn1L17dy1ZskTPPfecEhIS1L59+7/0XOZTTz2l3377Te+8847eeust7dy5U3379lVBQYEkadasWerQoYNCQ0O1bt06x/JXe120aJEGDRokSUpISNC6des0ePDgMl+HJP3vf//TP//5T40cOVIJCQm67bbbSrX/1q1bdd111yktLU2vvPKKvvjiC/Xu3VsjR47UhAkTLrj/zz//rJiYGL3//vv64osvNGjQIL300kt66KGHitSmp6fr3nvv1X333aclS5aoV69eGjt2rD744ANHzR9//KHOnTsrLS1Ns2bN0vvvv68TJ05o+PDhpbqugoIC5efnOy2StH//fgUGBurFF19UQkKCZs6cKXd3d7Vp08bpB6XixMbGavHixXr22We1bNkyvfPOO+rWrZuOHDniqPnggw/Uo0cP+fv7a968efroo48UEBCg6OjoUgXlyZMn6/Dhw3rppZfOW1eS8zVt2lS1atVyCvMrVqyQj4+Ptm7dqv3790uS8vPzlZSUpG7dukk6/Yx079695enpqTlz5ighIUEvvviifH19lZubW+JrAS4bFgCUQXp6uiXJuvvuu0tUv23bNkuSNXToUKf1GzZssCRZTz31lGNdnTp1rAEDBhQ5RufOna3OnTs7Xq9cudKSZN10001OdR999JElyVq3bp1jXe/eva06deqUe6/jxo2zJFmHDh0q0bHPvpamTZs6ratTp47l5uZm7dixw2n97t27LUnW3LlzixxHkjVu3DjH6+joaOvKK6+0MjMzneqGDx9ueXt7W0ePHi1xjwUFBVZeXp713nvvWW5ubk77du7c2ZJkbdiwwWmfJk2aWNHR0Y7XTzzxhGWz2azU1FSnuu7du1uSrJUrV563h7lz51qSil3y8vKK1Ofn51u5ublW/fr1rccee8yxvrj3sFq1alZcXNw5z52dnW0FBARYffv2LfK+tGjRwrr++uvP2/uZc7700kuWZVnWvffea/n6+loHDhywLKvo105pznffffdZV111leN1t27drCFDhlg1atSw5s2bZ1mWZX333XeWJGvZsmWWZVnWxx9/bEkq8m8BoHiMJAOoECtXrpSkIo9RXH/99WrcuHGpRuVMZz/SIUnNmzeXJP32229lOt7F7PVCmjdvrgYNGpRp31OnTumbb77RrbfeqqpVqzqNut500006deqU1q9ff95j/PDDD+rXr58CAwPl5uYmDw8P3X///SooKNBPP/3kVBsaGqrrr7++SP9nv+8rV65U06ZN1aJFC6e6mJiYUl3be++9p+TkZKfF3d1d+fn5mjhxopo0aSJPT0+5u7vL09NTO3fu1LZt2857zOuvv17x8fF6/vnntX79+iKPlKxdu1ZHjx7VgAEDnN7LwsJC9ezZU8nJycrOzi7xNTz//PPKy8s754h+ac7XtWtX/fLLL9q9e7dOnTqlNWvWqGfPnurSpYuWL18u6fTospeXl2644QZJUsuWLeXp6akHH3xQ8+bN0y+//FLi3oHLESEZQJkEBQWpatWq2r17d4nqz/wKu7jZG8LCwpx+xV1agYGBTq/PPB998uTJMh3vYvZ6IX9ldosjR44oPz9f06dPl4eHh9Ny0003SdJ5H2vZs2ePOnbsqN9//12vvfaaVq9ereTkZMfzzOb7ab7v0un3/uy6I0eOKDQ0tEhdcevOp3HjxmrdurXTIkmjRo3SM888o1tuuUWff/65NmzYoOTkZLVo0eKC//4ffvihBgwYoHfeeUft2rVTQECA7r//fqWnp0s6/aiIJN1+++1F3s/JkyfLsqxSTXFYt25dDR06VO+884527txZZHtpznfmEYoVK1ZozZo1ysvL04033qhu3bo5fohbsWKFOnTo4Pjg59VXX60VK1YoODhYw4YN09VXX62rr75ar732WomvAbicMLsFgDJxc3NT165dtXTpUu3bt09XXnnleevPBKoDBw4Uqd2/f7+CgoIcr729vZWTk1PkGIcPH3aqu1hK02t5K+4Dhd7e3pJU5D0xw3qNGjXk5uam2NhYDRs2rNjj16tX75znXrx4sbKzs/Xpp5+qTp06jvWpqaklbb+IwMBAR+g8W3HryuKDDz7Q/fffr4kTJzqtP3z4cLFzVp8tKChI06ZN07Rp07Rnzx4tWbJETz75pA4ePKiEhATHv/P06dPPOQtJSEhIqfr917/+pTlz5uipp54q8iG70pzvyiuvVIMGDbRixQrVrVtXrVu3VvXq1dW1a1cNHTpUGzZs0Pr164uMWnfs2FEdO3ZUQUGBNm7cqOnTpysuLk4hISG6++67S3UtwN8dI8kAymzs2LGyLEtDhgwp9oM/eXl5+vzzzyWd/oS/JKcPdUlScnKytm3bpq5duzrW1a1bV5s2bXKq++mnny74QazzMUc4z6c0vVaEkJAQeXt7F3lPPvvsM6fXVatWVZcuXfTDDz+oefPmRUZeW7duXezo7xlnAvrZM5VYlqW33367zL136dJFW7Zs0Y8//ui0fsGCBWU+5tlsNluRmVW+/PJL/f7776U6Tu3atTV8+HB1795d//vf/yRJHTp0UPXq1bV169Zi38vWrVvL09OzVOcJDAzUE088oY8//ljff/+907bSnq9bt25KTEzU8uXL1b17d0lSgwYNVLt2bT377LPKy8tzjDib3Nzc1KZNG8dvCc5cM4D/j5FkAGXWrl07zZ49W0OHDlVkZKQeeeQRNW3aVHl5efrhhx/01ltvKSIiQn379lXDhg314IMPavr06apSpYp69eqlX3/9Vc8884zCw8P12GOPOY4bGxur++67T0OHDtVtt92m3377TVOmTFHNmjXL3GuzZs306aefavbs2YqMjFSVKlXOOe9uaXqtCDabTffdd5/mzJmjq6++Wi1atND3339fbNB87bXXdMMNN6hjx4565JFHVLduXR0/fly7du3S559/rsTExHOep3v37vL09NQ999yjxx9/XKdOndLs2bOVkZFR5t7j4uI0Z84c9e7dW88//7xCQkI0f/58bd++vczHPFufPn0UHx+vRo0aqXnz5kpJSdFLL710wd9sZGZmqkuXLoqJiVGjRo3k5+en5ORkJSQkqH///pKkatWqafr06RowYICOHj2q22+/XcHBwTp06JB+/PFHHTp0SLNnzy51z3FxcZo5c6aWLl3qtL605+vatatmzZqlw4cPO/01ya5du2ru3LmqUaOG0/Rvb7zxhhITE9W7d2/Vrl1bp06d0pw5cyTpnGEauKy59nODAP4OUlNTrQEDBli1a9e2PD09LV9fX6tVq1bWs88+ax08eNBRV1BQYE2ePNlq0KCB5eHhYQUFBVn33XeftXfvXqfjFRYWWlOmTLGuuuoqy9vb22rdurWVmJh4ztkt/vvf/zrtX9xMBkePHrVuv/12q3r16pbNZrMudPsraa/lPbtF7969i63PzMy0Bg8ebIWEhFi+vr5W3759rV9//bXI7BaWdfr6//GPf1hXXHGF5eHhYdWsWdNq37699fzzz1+wr88//9xq0aKF5e3tbV1xxRXWP//5T2vp0qVFZqIorn/LsqwBAwYUmUVk69atVvfu3S1vb28rICDAGjRokPXZZ5+VanaL5OTkYrdnZGRYgwYNsoKDg62qVataN9xwg7V69eoiXyvm18SpU6eshx9+2GrevLnl7+9v+fj4WA0bNrTGjRtnZWdnO50jKSnJ6t27txUQEGB5eHhYV1xxhdW7d+8iX3cmc3aLs7311luOWTrMr52Sni8jI8OqUqWK5evra+Xm5jrWz58/35Jk9e/f36l+3bp11q233mrVqVPH8vLysgIDA63OnTtbS5YsOe91AJcrm2VZlkvSOQAAAFBJ8UwyAAAAYCAkAwAAAAZCMgAAAGAgJAMAAAAGQjIAAABgICQDAAAABv6YSDkqLCzU/v375efnV+yflgUAAIBrWZal48ePKywsTFWqnHu8mJBcjvbv36/w8HBXtwEAAIAL2Lt373n/OichuRz5+flJOv2m+/v7u7gbAAAAmLKyshQeHu7IbedCSC5HZx6x8Pf3JyQDAABUYhd6NJYP7gEAAAAGQjIAAABgICQDAAAABkIyAAAAYCAkAwAAAAZCMgAAAGAgJAMX2aRJk3TdddfJz89PwcHBuuWWW7Rjxw6nmvHjx6tRo0by9fVVjRo11K1bN23YsKHY41mWpV69eslms2nx4sVO23766SfdfPPNCgoKkr+/vzp06KCVK1c61Tz66KOKjIyUl5eXWrZsWZ6XCgDA3wYhGbjIkpKSNGzYMK1fv17Lly9Xfn6+evTooezsbEdNgwYNNGPGDG3evFlr1qxR3bp11aNHDx06dKjI8aZNm3bOuR179+6t/Px8JSYmKiUlRS1btlSfPn2Unp7uqLEsS//4xz901113lf/FAgDwN2GzLMtydRN/F1lZWbLb7crMzOSPieCcDh06pODgYCUlJalTp07F1pz5WlqxYoW6du3qWP/jjz+qT58+Sk5OVq1atbRo0SLdcsstkqTDhw+rZs2a+vbbb9WxY0dJ0vHjx+Xv71/kONLp0evFixcrNTX1olwnAACVUUnzGiPJQAXLzMyUJAUEBBS7PTc3V2+99ZbsdrtatGjhWP/nn3/qnnvu0YwZMxQaGlpkv8DAQDVu3FjvvfeesrOzlZ+frzfffFMhISGKjIy8OBcDAMDfFH+WGqhAlmVp1KhRuuGGGxQREeG07YsvvtDdd9+tP//8U7Vq1dLy5csVFBTk2P7YY4+pffv2uvnmm4s9ts1m0/Lly3XzzTfLz89PVapUUUhIiBISElS9evWLeVkAAPztEJKBCjR8+HBt2rRJa9asKbKtS5cuSk1N1eHDh/X222/rzjvv1IYNGxQcHKwlS5YoMTFRP/zwwzmPbVmWhg4dquDgYK1evVo+Pj565513nB7PAAAAJcPjFkAFGTFihJYsWaKVK1fqyiuvLLLd19dX11xzjdq2bat3331X7u7uevfddyVJiYmJ+vnnn1W9enW5u7vL3f30z7e33XaboqKiHDVffPGFFi5cqA4dOujaa6/VrFmz5OPjo3nz5lXYdQIA8HfASDJwkVmWpREjRmjRokVatWqV6tWrV+L9cnJyJElPPvmkBg8e7LS9WbNmevXVV9W3b19Jp59ZlqQqVZx/9q1SpYoKCwv/6mUAAHBZISQDF9mwYcO0YMECffbZZ/Lz83NMx2a32+Xj46Ps7Gy98MIL6tevn2rVqqUjR45o1qxZ2rdvn+644w5JUmhoaLEf1qtdu7YjdLdr1041atTQgAED9Oyzz8rHx0dvv/22du/erd69ezv22bVrl06cOKH09HSdPHnSMbtFkyZN5OnpeZHfDQAALg2EZOAimz17tiQ5Hos4Y+7cuRo4cKDc3Ny0fft2zZs3T4cPH1ZgYKCuu+46rV69Wk2bNi3xeYKCgpSQkKCnn35aN954o/Ly8tS0aVN99tlnTrNkDB48WElJSY7XrVq1kiTt3r1bdevWLfuFAgDwN8I8yeWIeZIBAAAqN+ZJBgAAAMqIkAwAAAAYeCYZLmebMMHVLeAyYY0b5+oWAACXCEaSAQAAAAMhGQAAADAQkgEAAAADIRkAAAAwEJIBAAAAAyEZAAAAMBCSAQAAAAMhGQAAADAQkgEAAAADIRkAAAAwEJIBAAAAAyEZAAAAMBCSAQAAAAMhGQAAADAQkgEAAAADIRkAAAAwEJIBAAAAAyEZAAAAMBCSAQAAAAMhGQAAADAQkgEAAAADIRkAAAAwEJIBAAAAAyEZAAAAMBCSAQAAAAMhGQAAlMqkSZN03XXXyc/PT8HBwbrlllu0Y8cOp5pPP/1U0dHRCgoKks1mU2pq6jmPZ1mWevXqJZvNpsWLFztte+GFF9S+fXtVrVpV1atXL7JvfHy8bDZbscvBgwfL4WpxuSIkAwCAUklKStKwYcO0fv16LV++XPn5+erRo4eys7MdNdnZ2erQoYNefPHFCx5v2rRpstlsxW7Lzc3VHXfcoUceeaTY7XfddZcOHDjgtERHR6tz584KDg4u2wUCktxd3QAAALi0JCQkOL2eO3eugoODlZKSok6dOkmSYmNjJUm//vrreY/1448/aurUqUpOTlatWrWKbJ8wYYKk0yPGxfHx8ZGPj4/j9aFDh5SYmKh33323pJcDFIuRZAAA8JdkZmZKkgICAkq1359//ql77rlHM2bMUGhoaLn08t5776lq1aq6/fbby+V4uHwRkgEAQJlZlqVRo0bphhtuUERERKn2feyxx9S+fXvdfPPN5dbPnDlzFBMT4zS6DJQFj1sAAIAyGz58uDZt2qQ1a9aUar8lS5YoMTFRP/zwQ7n1sm7dOm3dulXvvfdeuR0Tly9GkgEAQJmMGDFCS5Ys0cqVK3XllVeWat/ExET9/PPPql69utzd3eXufnrc7rbbblNUVFSZ+nnnnXfUsmVLRUZGlml/4GyMJAMAgFKxLEsjRozQokWLtGrVKtWrV6/Ux3jyySc1ePBgp3XNmjXTq6++qr59+5b6eCdOnNBHH32kSZMmlXpfoDiEZAAAUCrDhg3TggUL9Nlnn8nPz0/p6emSJLvd7ngW+OjRo9qzZ4/2798vSY55lENDQ50WU+3atZ1C9549exzHKigocMy3fM0116hatWqOug8//FD5+fm69957L8o14/LD4xYAAKBUZs+erczMTEVFRalWrVqO5cMPP3TULFmyRK1atVLv3r0lSXfffbdatWqlN954o1TnevbZZ9WqVSuNGzdOJ06cUKtWrdSqVStt3LjRqe7dd99V//79VaNGjb9+gYAkm2VZlqub+LvIysqS3W5XZmam/P39Xd3OJcP2f3NgAhebNW6cq1sAALhYSfMaI8kAAACAgWeSAQAob9uL/xPLQLlrxAMBFwsjyQAAAICBkAwAAAAYCMkAAACAgZAMAAAAGAjJAAAAgIGQDAAAABgIyQAAAICBkAwAAAAYCMkAAACAgZAMAAAAGAjJAAAAgIGQDAAAABgIyQAAAICBkAwAAAAYCMkAAACAgZAMAAAAGAjJAAAAgIGQDAAAABgIyQAAAICBkAwAAAAYCMkAAACAgZAMAAAAGFwakidNmqTrrrtOfn5+Cg4O1i233KIdO3Y41ViWpfHjxyssLEw+Pj6KiorSli1bnGpycnI0YsQIBQUFydfXV/369dO+ffucajIyMhQbGyu73S673a7Y2FgdO3bMqWbPnj3q27evfH19FRQUpJEjRyo3N/eiXDsAAAAqL5eG5KSkJA0bNkzr16/X8uXLlZ+frx49eig7O9tRM2XKFE2dOlUzZsxQcnKyQkND1b17dx0/ftxRExcXp0WLFmnhwoVas2aNTpw4oT59+qigoMBRExMTo9TUVCUkJCghIUGpqamKjY11bC8oKFDv3r2VnZ2tNWvWaOHChfrkk080evToinkzAAAAUGnYLMuyXN3EGYcOHVJwcLCSkpLUqVMnWZalsLAwxcXF6YknnpB0etQ4JCREkydP1kMPPaTMzEzVrFlT77//vu666y5J0v79+xUeHq6vvvpK0dHR2rZtm5o0aaL169erTZs2kqT169erXbt22r59uxo2bKilS5eqT58+2rt3r8LCwiRJCxcu1MCBA3Xw4EH5+/tfsP+srCzZ7XZlZmaWqB6n2SZMcHULuExY48a5ugVcLrbbXN0BLheNKk2Mu2SUNK9VqmeSMzMzJUkBAQGSpN27dys9PV09evRw1Hh5ealz585au3atJCklJUV5eXlONWFhYYqIiHDUrFu3Tna73RGQJalt27ay2+1ONREREY6ALEnR0dHKyclRSkpKsf3m5OQoKyvLaQEAAMClr9KEZMuyNGrUKN1www2KiIiQJKWnp0uSQkJCnGpDQkIc29LT0+Xp6akaNWqctyY4OLjIOYODg51qzPPUqFFDnp6ejhrTpEmTHM842+12hYeHl/ayAQAAUAlVmpA8fPhwbdq0Sf/5z3+KbLPZnH9tZVlWkXUms6a4+rLUnG3s2LHKzMx0LHv37j1vTwAAALg0VIqQPGLECC1ZskQrV67UlVde6VgfGhoqSUVGcg8ePOgY9Q0NDVVubq4yMjLOW/PHH38UOe+hQ4ecaszzZGRkKC8vr8gI8xleXl7y9/d3WgAAAHDpc2lItixLw4cP16effqrExETVq1fPaXu9evUUGhqq5cuXO9bl5uYqKSlJ7du3lyRFRkbKw8PDqebAgQNKS0tz1LRr106ZmZn6/vvvHTUbNmxQZmamU01aWpoOHDjgqFm2bJm8vLwUGRlZ/hcPAACASsvdlScfNmyYFixYoM8++0x+fn6OkVy73S4fHx/ZbDbFxcVp4sSJql+/vurXr6+JEyeqatWqiomJcdQOGjRIo0ePVmBgoAICAjRmzBg1a9ZM3bp1kyQ1btxYPXv21JAhQ/Tmm29Kkh588EH16dNHDRs2lCT16NFDTZo0UWxsrF566SUdPXpUY8aM0ZAhQxghBgAAuMy4NCTPnj1bkhQVFeW0fu7cuRo4cKAk6fHHH9fJkyc1dOhQZWRkqE2bNlq2bJn8/Pwc9a+++qrc3d1155136uTJk+ratavi4+Pl5ubmqJk/f75GjhzpmAWjX79+mjFjhmO7m5ubvvzySw0dOlQdOnSQj4+PYmJi9PLLL1+kqwcAAEBlVanmSb7UMU9y2TBPMioK8ySjwjBPMioK8ySX2iU5TzIAAABQGRCSAQAAAAMhGQAAADAQkgEAAAADIRkAAAAwEJIBAAAAAyEZAAAAMBCSAQAAAAMhGQAAADAQkgEAAAADIRkAAAAwEJIBAAAAAyEZAAAAMBCSAQAAAAMhGQAAADAQkgEAAAADIRkAAAAwEJIBAAAAAyEZAAAAMBCSAQAAAAMhGQAAADAQkgEAAAADIRkAAAAwEJIBAAAAAyEZAAAAMBCSAQAAAAMhGQAAADAQkgEAAAADIRkAAAAwEJIBAAAAAyEZAAAAMBCSAQAAAAMhGQAAADAQkgEAAAADIRkAAAAwEJIBAAAAAyEZAAAAMBCSAQAAAAMhGQAAADAQkgEAAAADIRkAAAAwEJIBAAAAAyEZAAAAMBCSAQAAAAMhGQAAADAQkgEAAAADIRkAAAAwEJIBAAAAAyEZAAAAMBCSAQAAAAMhGQAAADAQkgEAAAADIRkAAAAwEJIBAAAAAyEZAAAAMBCSAQAAAAMhGQAAADAQkgEAAAADIRkAAAAwEJIBAAAAAyEZAAAAMBCSAQAAAAMhGQAAADAQkgEAAAADIRkAAAAwEJIBAAAAAyEZAAAAMBCSAQAAAAMhGQAAADAQkgEAAAADIRkAAAAwEJIBAAAAAyEZAAAAMBCSAQAAAAMhGQAAADAQkgEAAAADIRkAAAAwEJIBAAAAAyEZAAAAMBCSAQAAAAMhGQAAADAQkgEAAAADIRkAAAAwuDQkf/vtt+rbt6/CwsJks9m0ePFip+0DBw6UzWZzWtq2betUk5OToxEjRigoKEi+vr7q16+f9u3b51STkZGh2NhY2e122e12xcbG6tixY041e/bsUd++feXr66ugoCCNHDlSubm5F+OyAQAAUMm5NCRnZ2erRYsWmjFjxjlrevbsqQMHDjiWr776yml7XFycFi1apIULF2rNmjU6ceKE+vTpo4KCAkdNTEyMUlNTlZCQoISEBKWmpio2NtaxvaCgQL1791Z2drbWrFmjhQsX6pNPPtHo0aPL/6IBAABQ6bm78uS9evVSr169zlvj5eWl0NDQYrdlZmbq3Xff1fvvv69u3bpJkj744AOFh4drxYoVio6O1rZt25SQkKD169erTZs2kqS3335b7dq1044dO9SwYUMtW7ZMW7du1d69exUWFiZJeuWVVzRw4EC98MIL8vf3L8erBgAAQGVX6Z9JXrVqlYKDg9WgQQMNGTJEBw8edGxLSUlRXl6eevTo4VgXFhamiIgIrV27VpK0bt062e12R0CWpLZt28putzvVREREOAKyJEVHRysnJ0cpKSnn7C0nJ0dZWVlOCwAAAC59lTok9+rVS/Pnz1diYqJeeeUVJScn68Ybb1ROTo4kKT09XZ6enqpRo4bTfiEhIUpPT3fUBAcHFzl2cHCwU01ISIjT9ho1asjT09NRU5xJkyY5nnO22+0KDw//S9cLAACAysGlj1tcyF133eX474iICLVu3Vp16tTRl19+qf79+59zP8uyZLPZHK/P/u+/UmMaO3asRo0a5XidlZVFUAYAAPgbqNQjyaZatWqpTp062rlzpyQpNDRUubm5ysjIcKo7ePCgY2Q4NDRUf/zxR5FjHTp0yKnGHDHOyMhQXl5ekRHms3l5ecnf399pAQAAwKXvkgrJR44c0d69e1WrVi1JUmRkpDw8PLR8+XJHzYEDB5SWlqb27dtLktq1a6fMzEx9//33jpoNGzYoMzPTqSYtLU0HDhxw1CxbtkxeXl6KjIysiEsDAABAJeLSxy1OnDihXbt2OV7v3r1bqampCggIUEBAgMaPH6/bbrtNtWrV0q+//qqnnnpKQUFBuvXWWyVJdrtdgwYN0ujRoxUYGKiAgACNGTNGzZo1c8x20bhxY/Xs2VNDhgzRm2++KUl68MEH1adPHzVs2FCS1KNHDzVp0kSxsbF66aWXdPToUY0ZM0ZDhgxhdBgAAOAy5NKQvHHjRnXp0sXx+szzvQMGDNDs2bO1efNmvffeezp27Jhq1aqlLl266MMPP5Sfn59jn1dffVXu7u668847dfLkSXXt2lXx8fFyc3Nz1MyfP18jR450zILRr18/p7mZ3dzc9OWXX2ro0KHq0KGDfHx8FBMTo5dffvlivwUAAACohGyWZVmubuLvIisrS3a7XZmZmYxAl4JtwgRXt4DLhDVunKtbwOVi+7k/9A2Uq0bEuNIqaV67pJ5JBgAAACoCIRkAAAAwEJIBAAAAAyEZAAAAMBCSAQAAAAMhGQAAADAQkgEAAAADIRkAAAAwEJIBAAAAAyEZAAAAMBCSAQAAAAMhGQAAADAQkgEAAAADIRkAAAAwEJIBAAAAAyEZAAAAMBCSAQAAAAMhGQAAADAQkgEAAAADIRkAAAAwEJIBAAAAAyEZAAAAMBCSAQAAAAMhGQAAADAQkgEAAABDmULyVVddpSNHjhRZf+zYMV111VV/uSkAAADAlcoUkn/99VcVFBQUWZ+Tk6Pff//9LzcFAAAAuJJ7aYqXLFni+O+vv/5adrvd8bqgoEDffPON6tatW27NAQAAAK5QqpB8yy23SJJsNpsGDBjgtM3Dw0N169bVK6+8Um7NAQAAAK5QqpBcWFgoSapXr56Sk5MVFBR0UZoCAAAAXKlUIfmM3bt3l3cfAAAAQKVRppAsSd98842++eYbHTx40DHCfMacOXP+cmMAAACAq5QpJE+YMEH//ve/1bp1a9WqVUs2m628+wIAAABcpkwh+Y033lB8fLxiY2PLux8AAADA5co0T3Jubq7at29f3r0AAAAAlUKZQvLgwYO1YMGC8u4FAAAAqBTK9LjFqVOn9NZbb2nFihVq3ry5PDw8nLZPnTq1XJoDAAAAXKFMIXnTpk1q2bKlJCktLc1pGx/iAwAAwKWuTCF55cqV5d0HAAAAUGmU6ZlkAAAA4O+sTCPJXbp0Oe9jFYmJiWVuCAAAAHC1MoXkM88jn5GXl6fU1FSlpaVpwIAB5dEXAAAA4DJlCsmvvvpqsevHjx+vEydO/KWGAAAAAFcr12eS77vvPs2ZM6c8DwkAAABUuHINyevWrZO3t3d5HhIAAACocGV63KJ///5Ory3L0oEDB7Rx40Y988wz5dIYAAAA4CplCsl2u93pdZUqVdSwYUP9+9//Vo8ePcqlMQAAAMBVyhSS586dW959AAAAAJVGmULyGSkpKdq2bZtsNpuaNGmiVq1alVdfAAAAgMuUKSQfPHhQd999t1atWqXq1avLsixlZmaqS5cuWrhwoWrWrFnefQIAAAAVpkyzW4wYMUJZWVnasmWLjh49qoyMDKWlpSkrK0sjR44s7x4BAACAClWmkeSEhAStWLFCjRs3dqxr0qSJZs6cyQf3AAAAcMkr00hyYWGhPDw8iqz38PBQYWHhX24KAAAAcKUyheQbb7xRjz76qPbv3+9Y9/vvv+uxxx5T165dy605AAAAwBXKFJJnzJih48ePq27durr66qt1zTXXqF69ejp+/LimT59e3j0CAAAAFapMzySHh4frf//7n5YvX67t27fLsiw1adJE3bp1K+/+AAAAgApXqpHkxMRENWnSRFlZWZKk7t27a8SIERo5cqSuu+46NW3aVKtXr74ojQIAAAAVpVQhedq0aRoyZIj8/f2LbLPb7XrooYc0derUcmsOAAAAcIVSheQff/xRPXv2POf2Hj16KCUl5S83BQAAALhSqULyH3/8UezUb2e4u7vr0KFDf7kpAAAAwJVKFZKvuOIKbd68+ZzbN23apFq1av3lpgAAAABXKlVIvummm/Tss8/q1KlTRbadPHlS48aNU58+fcqtOQAAAMAVSjUF3L/+9S99+umnatCggYYPH66GDRvKZrNp27ZtmjlzpgoKCvT0009frF4BAACAClGqkBwSEqK1a9fqkUce0dixY2VZliTJZrMpOjpas2bNUkhIyEVpFAAAAKgopf5jInXq1NFXX32ljIwM7dq1S5ZlqX79+qpRo8bF6A8AAACocGX6i3uSVKNGDV133XXl2QsAAABQKZTqg3sAAADA5YCQDAAAABgIyQAAAICBkAwAAAAYCMkAAACAgZAMAAAAGAjJAAAAgIGQDAAAABgIyQAAAICBkAwAAAAYCMkAAACAgZAMAAAAGAjJAAAAgIGQDAAAABgIyQAAAICBkAwAAAAYXBqSv/32W/Xt21dhYWGy2WxavHix03bLsjR+/HiFhYXJx8dHUVFR2rJli1NNTk6ORowYoaCgIPn6+qpfv37at2+fU01GRoZiY2Nlt9tlt9sVGxurY8eOOdXs2bNHffv2la+vr4KCgjRy5Ejl5uZejMsGAABAJefSkJydna0WLVpoxowZxW6fMmWKpk6dqhkzZig5OVmhoaHq3r27jh8/7qiJi4vTokWLtHDhQq1Zs0YnTpxQnz59VFBQ4KiJiYlRamqqEhISlJCQoNTUVMXGxjq2FxQUqHfv3srOztaaNWu0cOFCffLJJxo9evTFu3gAAABUWjbLsixXNyFJNptNixYt0i233CLp9ChyWFiY4uLi9MQTT0g6PWocEhKiyZMn66GHHlJmZqZq1qyp999/X3fddZckaf/+/QoPD9dXX32l6Ohobdu2TU2aNNH69evVpk0bSdL69evVrl07bd++XQ0bNtTSpUvVp08f7d27V2FhYZKkhQsXauDAgTp48KD8/f1LdA1ZWVmy2+3KzMws8T6QbBMmuLoFXCasceNc3QIuF9ttru4Al4tGlSLGXVJKmtcq7TPJu3fvVnp6unr06OFY5+Xlpc6dO2vt2rWSpJSUFOXl5TnVhIWFKSIiwlGzbt062e12R0CWpLZt28putzvVREREOAKyJEVHRysnJ0cpKSnn7DEnJ0dZWVlOCwAAAC59lTYkp6enS5JCQkKc1oeEhDi2paeny9PTUzVq1DhvTXBwcJHjBwcHO9WY56lRo4Y8PT0dNcWZNGmS4zlnu92u8PDwUl4lAAAAKqNKG5LPsNmcf2VlWVaRdSazprj6stSYxo4dq8zMTMeyd+/e8/YFAACAS0OlDcmhoaGSVGQk9+DBg45R39DQUOXm5iojI+O8NX/88UeR4x86dMipxjxPRkaG8vLyiowwn83Ly0v+/v5OCwAAAC59lTYk16tXT6GhoVq+fLljXW5urpKSktS+fXtJUmRkpDw8PJxqDhw4oLS0NEdNu3btlJmZqe+//95Rs2HDBmVmZjrVpKWl6cCBA46aZcuWycvLS5GRkRf1OgEAAFD5uLvy5CdOnNCuXbscr3fv3q3U1FQFBASodu3aiouL08SJE1W/fn3Vr19fEydOVNWqVRUTEyNJstvtGjRokEaPHq3AwEAFBARozJgxatasmbp16yZJaty4sXr27KkhQ4bozTfflCQ9+OCD6tOnjxo2bChJ6tGjh5o0aaLY2Fi99NJLOnr0qMaMGaMhQ4YwOgwAAHAZcmlI3rhxo7p06eJ4PWrUKEnSgAEDFB8fr8cff1wnT57U0KFDlZGRoTZt2mjZsmXy8/Nz7PPqq6/K3d1dd955p06ePKmuXbsqPj5ebm5ujpr58+dr5MiRjlkw+vXr5zQ3s5ubm7788ksNHTpUHTp0kI+Pj2JiYvTyyy9f7LcAAAAAlVClmSf574B5ksuGeZJRUZgnGRWGeZJRUZgnudQu+XmSAQAAAFchJAMAAAAGQjIAAABgICQDAAAABkIyAAAAYCAkAwAAAAZCMgAAAGAgJAMAAAAGQjIAAABgICQDAAAABkIyAAAAYCAkAwAAAAZCMgAAAGAgJAMAAAAGQjIAAABgICQDAAAABkIyAAAAYCAkAwAAAAZCMgAAAGAgJAMAAAAGQjIAAABgICQDAAAABkIyAAAAYCAkAwAAAAZCMgAAAGAgJAMAAAAGQjIAAABgICQDAAAABkIyAAAAYCAkAwAAAAZCMgAAAGAgJAMAAAAGQjIAAABgICQDAAAABkIyAAAAYCAkAwAAAAZCMgAAAGAgJAMAAAAGQjIAAABgICQDAAAABkIyAAAAYCAkAwAAAAZCMgAAAGAgJAMAAAAGQjIAAABgICQDAAAABkIyAAAAYCAkAwAAAAZCMgAAAGAgJAMAAAAGQjIAAABgICQDAAAABkIyAAAAYCAkAwAAAAZCMgAAAGAgJAMAAAAGQjIAAABgICQDAAAABkIyAAAAYCAkAwAAAAZCMgAAAGAgJAMAAAAGQjIAAABgICQDAAAABkIyAAAAYCAkAwAAAAZCMgAAAGAgJAMAAAAGQjIAAABgICQDAAAABkIyAAAAYCAkAwAAAAZCMgAAAGAgJAMAAAAGQjIAAABgICQDAAAABkIyAAAAYCAkAwAAAAZCMgAAAGAgJAMAAAAGQjIAAABgICQDAAAABkIyAAAAYKjUIXn8+PGy2WxOS2hoqGO7ZVkaP368wsLC5OPjo6ioKG3ZssXpGDk5ORoxYoSCgoLk6+urfv36ad++fU41GRkZio2Nld1ul91uV2xsrI4dO1YRlwgAAIBKqFKHZElq2rSpDhw44Fg2b97s2DZlyhRNnTpVM2bMUHJyskJDQ9W9e3cdP37cURMXF6dFixZp4cKFWrNmjU6cOKE+ffqooKDAURMTE6PU1FQlJCQoISFBqampio2NrdDrBAAAQOXh7uoGLsTd3d1p9PgMy7I0bdo0Pf300+rfv78kad68eQoJCdGCBQv00EMPKTMzU++++67ef/99devWTZL0wQcfKDw8XCtWrFB0dLS2bdumhIQErV+/Xm3atJEkvf3222rXrp127Nihhg0bVtzFAgAAoFKo9CPJO3fuVFhYmOrVq6e7775bv/zyiyRp9+7dSk9PV48ePRy1Xl5e6ty5s9auXStJSklJUV5enlNNWFiYIiIiHDXr1q2T3W53BGRJatu2rex2u6PmXHJycpSVleW0AAAA4NJXqUNymzZt9N577+nrr7/W22+/rfT0dLVv315HjhxRenq6JCkkJMRpn5CQEMe29PR0eXp6qkaNGuetCQ4OLnLu4OBgR825TJo0yfEcs91uV3h4eJmvFQAAAJVHpQ7JvXr10m233aZmzZqpW7du+vLLLyWdfqziDJvN5rSPZVlF1pnMmuLqS3KcsWPHKjMz07Hs3bv3gtcEAACAyq9Sh2STr6+vmjVrpp07dzqeUzZHew8ePOgYXQ4NDVVubq4yMjLOW/PHH38UOdehQ4eKjFKbvLy85O/v77QAAADg0ndJheScnBxt27ZNtWrVUr169RQaGqrly5c7tufm5iopKUnt27eXJEVGRsrDw8Op5sCBA0pLS3PUtGvXTpmZmfr+++8dNRs2bFBmZqajBgAAAJeXSj27xZgxY9S3b1/Vrl1bBw8e1PPPP6+srCwNGDBANptNcXFxmjhxourXr6/69etr4sSJqlq1qmJiYiRJdrtdgwYN0ujRoxUYGKiAgACNGTPG8fiGJDVu3Fg9e/bUkCFD9Oabb0qSHnzwQfXp04eZLQAAAC5TlTok79u3T/fcc48OHz6smjVrqm3btlq/fr3q1KkjSXr88cd18uRJDR06VBkZGWrTpo2WLVsmPz8/xzFeffVVubu7684779TJkyfVtWtXxcfHy83NzVEzf/58jRw50jELRr9+/TRjxoyKvVgAAABUGjbLsixXN/F3kZWVJbvdrszMTJ5PLgXbhAmubgGXCWvcOFe3gMvF9vN/8BsoN42IcaVV0rx2ST2TDAAAAFQEQjIAAABgICQDAAAABkIyAAAAYCAkAwAAAAZCMgAAAGAgJAMAAAAGQjIAAABgICQDAAAABkIyAAAAYCAkAwAAAAZCMgAAAGAgJAMAAAAGQjIAAABgICQDAAAABkIyAAAAYCAkAwAAAAZCMgAAAGAgJAMAAAAGQjIAAABgICQDAAAABkIyAAAAYCAkAwAAAAZCMgAAAGAgJAMAAAAGQjIAAABgICQDAAAABkIyAAAAYCAkAwAAAAZCMgAAAGAgJAMAAAAGQjIAAABgICQDAAAABkIyAAAAYCAkAwAAAAZCMgAAAGAgJAMAAAAGQjIAAABgICQDAAAABkIyAAAAYCAkAwAAAAZCMgAAAGAgJAMAAAAGQjIAAABgICQDAAAABkIyAAAAYCAkAwAAAAZCMgAAAGAgJAMAAAAGQjIAAABgICQDAAAABkIyAAAAYCAkAwAAAAZCMgAAAGAgJAMAAAAGQjIAAABgICQDAAAABkIyAAAAYCAkAwAAAAZCMgAAAGAgJAMAAAAGQjIAAABgICQDAAAABkIyAAAAYCAkAwAAAAZCMgAAAGAgJAMAAAAGQjIAAABgICQDAAAABkIyAAAAYCAkAwAAAAZCMgAAAGAgJAMAAAAGQjIAAABgICQDAAAABkIyAAAAYCAkAwAAAAZCMgAAAGAgJAMAAAAGQjIAAABgICQDAAAABkIyAAAAYCAkAwAAAAZCsmHWrFmqV6+evL29FRkZqdWrV7u6JQAAAFQwQvJZPvzwQ8XFxenpp5/WDz/8oI4dO6pXr17as2ePq1sDAABABSIkn2Xq1KkaNGiQBg8erMaNG2vatGkKDw/X7NmzXd0aAAAAKpC7qxuoLHJzc5WSkqInn3zSaX2PHj20du3aYvfJyclRTk6O43VmZqYkKSsr6+I1+nd06pSrO8Blgv83UWFOuLoBXDa4r5Xame8FlmWdt46Q/H8OHz6sgoIChYSEOK0PCQlRenp6sftMmjRJEyZMKLI+PDz8ovQI4K+xv/iiq1sAgHJmd3UDl6zjx4/Lbj/3+0dINthsNqfXlmUVWXfG2LFjNWrUKMfrwsJCHT16VIGBgefcBygPWVlZCg8P1969e+Xv7+/qdgDgL+O+hopiWZaOHz+usLCw89YRkv9PUFCQ3NzciowaHzx4sMjo8hleXl7y8vJyWle9evWL1SJQhL+/P99MAPytcF9DRTjfCPIZfHDv/3h6eioyMlLLly93Wr98+XK1b9/eRV0BAADAFRhJPsuoUaMUGxur1q1bq127dnrrrbe0Z88ePfzww65uDQAAABWIkHyWu+66S0eOHNG///1vHThwQBEREfrqq69Up04dV7cGOPHy8tK4ceOKPO4DAJcq7muobGzWhea/AAAAAC4zPJMMAAAAGAjJAAAAgIGQDAAAABgIycBFFB8fz9zZAABcggjJwAUMHDhQNputyLJr1y5Xt6b4+HjZbDb17NnTaf2xY8dks9m0atUq1zQG4JJQ3L3t7GXgwIEV1suZe+2Lxp+PX7x4MX/FFi5BSAZKoGfPnjpw4IDTUq9ePVe3JUlyd3fXN998o5UrV7q6FQCXmLPvadOmTZO/v7/Tutdee82pPi8v76L24+3trcmTJysjI+OingcoCUIyUAJeXl4KDQ11Wtzc3DR16lQ1a9ZMvr6+Cg8P19ChQ3XixIlzHufHH39Uly5d5OfnJ39/f0VGRmrjxo2O7WvXrlWnTp3k4+Oj8PBwjRw5UtnZ2eftzdfXVw888ICefPLJ89b9/vvvuuuuu1SjRg0FBgbq5ptv1q+//ipJ2rx5s6pUqaLDhw9LkjIyMlSlShXdcccdjv0nTZqkdu3aObbfe++9qlmzpnx8fFS/fn3NnTv3vOcHUPmcfU+z2+2y2WyO16dOnVL16tX10UcfKSoqSt7e3vrggw80fvx4tWzZ0uk406ZNU926dZ3WzZ07V40bN5a3t7caNWqkWbNmXbCfbt26KTQ0VJMmTTpv3fnuldOnT1ezZs0ctWdGomfOnOlYFx0drbFjx0q68H0Zly9CMvAXVKlSRa+//rrS0tI0b948JSYm6vHHHz9n/b333qsrr7xSycnJSklJ0ZNPPikPDw9Jp4NqdHS0+vfvr02bNunDDz/UmjVrNHz48Av2MX78eG3evFkff/xxsdv//PNPdenSRdWqVdO3336rNWvWqFq1aurZs6dyc3MVERGhwMBAJSUlSZK+/fZbBQYG6ttvv3UcY9WqVercubMk6ZlnntHWrVu1dOlSbdu2TbNnz1ZQUFCJ3zcAl44nnnhCI0eO1LZt2xQdHV2ifd5++209/fTTeuGFF7Rt2zZNnDhRzzzzjObNm3fe/dzc3DRx4kRNnz5d+/btK7bmQvfKqKgobdmyxfFDf1JSkoKCghz3t/z8fK1du9ZxPzvffRmXOQvAeQ0YMMByc3OzfH19Hcvtt99ebO1HH31kBQYGOl7PnTvXstvtjtd+fn5WfHx8sfvGxsZaDz74oNO61atXW1WqVLFOnjxZ7D5nH//JJ5+0GjRoYOXl5VkZGRmWJGvlypWWZVnWu+++azVs2NAqLCx07JuTk2P5+PhYX3/9tWVZltW/f39r+PDhlmVZVlxcnDV69GgrKCjI2rJli5WXl2dVq1bNWrp0qWVZltW3b1/rgQceOMc7BuBSZN6vdu/ebUmypk2b5lQ3btw4q0WLFk7rXn31VatOnTqO1+Hh4daCBQucap577jmrXbt25zz/gAEDrJtvvtmyLMtq27at9Y9//MOyLMtatGiRdXZcudC9srCw0AoKCrI+/vhjy7Isq2XLltakSZOs4OBgy7Isa+3atZa7u7t1/Phxy7LOf1/G5Y2RZKAEunTpotTUVMfy+uuvS5JWrlyp7t2764orrpCfn5/uv/9+HTly5JyPSIwaNUqDBw9Wt27d9OKLL+rnn392bEtJSVF8fLyqVavmWKKjo1VYWKjdu3dfsMcnnnhChw4d0pw5c4psS0lJ0a5du+Tn5+c4dkBAgE6dOuXoISoqyvFBv6SkJHXp0kWdOnVSUlKSkpOTdfLkSXXo0EGS9Mgjj2jhwoVq2bKlHn/8ca1du7ZU7yeAS0fr1q1LVX/o0CHt3btXgwYNcrqfPf/88073vPOZPHmy5s2bp61btxbZdqF7pc1mU6dOnbRq1SodO3ZMW7Zs0cMPP6yCggJt27ZNq1at0rXXXqtq1apJOv99GZc3QjJQAr6+vrrmmmscS61atfTbb7/ppptuUkREhD755BOlpKQ4nnk714dbxo8fry1btqh3795KTExUkyZNtGjRIklSYWGhHnroIacw/uOPP2rnzp26+uqrL9hj9erVNXbsWE2YMEF//vmn07bCwkJFRkY6HTs1NVU//fSTYmJiJP3/X1Hu2rVLaWlp6tixozp37qykpCStWrVKkZGR8vPzkyT16tVLv/32m+Li4rR//3517dpVY8aMKfP7C6Dy8vX1dXpdpUoVWZbltO7se15hYaGk049cnH2/SUtL0/r160t0zk6dOik6OlpPPfVUkW0luVee+aF/9erVatGihapXr+74oX/VqlWKiopyHO9892Vc3txd3QBwqdq4caPy8/P1yiuvqEqV0z9vfvTRRxfcr0GDBmrQoIEee+wx3XPPPZo7d65uvfVWXXvttdqyZYuuueaaMvc0YsQIvf7660U+kX7ttdfqww8/VHBwsPz9/Yvd98xzyc8//7xatGghf39/de7cWZMmTVJGRobj+b0zatasqYEDB2rgwIHq2LGj/vnPf+rll18uc+8ALg01a9ZUenq6LMtyTM2Wmprq2B4SEqIrrrhCv/zyi+69994yn+fFF19Uy5Yt1aBBA6f1JblXRkVF6dFHH9XHH3/sCMSdO3fWihUrtHbtWj366KNO9ee6L+PyxkgyUEZXX3218vPzNX36dP3yyy96//339cYbb5yz/uTJkxo+fLhWrVql3377Td99952Sk5PVuHFjSacfl1i3bp2GDRum1NRU7dy5U0uWLNGIESNK3JO3t7cmTJjgeBzkjHvvvVdBQUG6+eabtXr1au3evVtJSUl69NFHHR+OOfMryg8++MDxTaV58+bKzc3VN9984zTy8uyzz+qzzz7Trl27tGXLFn3xxReO6wDw9xYVFaVDhw5pypQp+vnnnzVz5kwtXbrUqWb8+PGaNGmSXnvtNf3000/avHmz5s6dq6lTp5b4PM2aNdO9996r6dOnO60vyb3yzA/98+fPd9y7oqKitHjxYp08eVI33HCDpAvfl3F5IyQDZdSyZUtNnTpVkydPVkREhObPn3/eaYvc3Nx05MgR3X///WrQoIHuvPNO9erVSxMmTJB0OpAmJSVp586d6tixo1q1aqVnnnlGtWrVKlVfAwYM0FVXXeW0rmrVqvr2229Vu3Zt9e/fX40bN9Y//vEPnTx50mlkuUuXLiooKHB8U7HZbOrYsaMkOb6pSJKnp6fGjh2r5s2bq1OnTnJzc9PChQtL1SeAS1Pjxo01a9YszZw5Uy1atND3339f5HGrwYMH65133lF8fLyaNWumzp07Kz4+vtTzyz/33HNFHu0oyb3SZrM5fvt15h7WvHlz2e12tWrVynHfu9B9GZc3m2V+9QEAAACXOUaSAQAAAAMhGQAAADAQkgEAAAADIRkAAAAwEJIBAAAAAyEZAAAAMBCSAQAAAAMhGQAAADAQkgEARcTHx6t69ep/+Tg2m02LFy/+y8cBgIpGSAaAv6mBAwfqlltucXUbAHBJIiQDAAAABkIyAFyGpk6dqmbNmsnX11fh4eEaOnSoTpw4UaRu8eLFatCggby9vdW9e3ft3bvXafvnn3+uyMhIeXt766qrrtKECROUn59fUZcBABcNIRkALkNVqlTR66+/rrS0NM2bN0+JiYl6/PHHnWr+/PNPvfDCC5o3b56+++47ZWVl6e6773Zs//rrr3Xfffdp5MiR2rp1q958803Fx8frhRdeqOjLAYByZ7Msy3J1EwCA8jdw4EAdO3asRB+c++9//6tHHnlEhw8flnT6g3sPPPCA1q9frzZt2kiStm/frsaNG2vDhg26/vrr1alTJ/Xq1Utjx451HOeDDz7Q448/rv3790s6/cG9RYsW8Ww0gEuOu6sbAABUvJUrV2rixInaunWrsrKylJ+fr1OnTik7O1u+vr6SJHd3d7Vu3dqxT6NGjVS9enVt27ZN119/vVJSUpScnOw0clxQUKBTp07pzz//VNWqVSv8ugCgvBCSAeAy89tvv+mmm27Sww8/rOeee04BAQFas2aNBg0apLy8PKdam81WZP8z6woLCzVhwgT179+/SI23t/fFaR4AKgghGQAuMxs3blR+fr5eeeUVValy+qMpH330UZG6/Px8bdy4Uddff70kaceOHTp27JgaNWokSbr22mu1Y8cOXXPNNRXXPABUEEIyAPyNZWZmKjU11WldzZo1lZ+fr+nTp6tv37767rvv9MYbbxTZ18PDQyNGjNDrr78uDw8PDR8+XG3btnWE5meffVZ9+vRReHi47rjjDlWpUkWbNm3S5s2b9fzzz1fE5QHARcPsFgDwN7Zq1Sq1atXKaZkzZ46mTp2qyZMnKyIiQvPnz9ekSZOK7Fu1alU98cQTiomJUbt27eTj46OFCxc6tkdHR+uLL77Q8uXLdd1116lt27aaOnWq6tSpU5GXCAAXBbNbAAAAAAZGkgEAAAADIRkAAAAwEJIBAAAAAyEZAAAAMBCSAQAAAAMhGQAAADAQkgEAAAADIRkAAAAwEJIBAAAAAyEZAAAAMBCSAQAAAMP/A7gVwMsudIaAAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the count of values for the label\n",
    "label_counts = df['label'].value_counts()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = label_counts.plot(kind='bar', color=['teal', 'gold'])\n",
    "\n",
    "# Adding count numbers on top of the bars\n",
    "for bar in bars.patches:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, height + 0.5, int(height), ha='center', va='bottom')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Count of True and False News')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0, ticks=[0, 1], labels=['False News', 'True News'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a9870e-8f49-4d36-ae30-60bfe14ea155",
   "metadata": {},
   "source": [
    "The class distribution shows that the dataset is relatively balanced, with a slight majority of fake news samples. The difference in the number of samples between the two classes is not substantial enough to warrant resampling. Hence we proceed with the data as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab83408-074f-4ea3-bbe7-0f62e7737923",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "395017e9-4865-429c-a756-69e0db6a55bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the lemmatizer and stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Convert to lower case\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    # Remove punctuation\n",
    "    tokens = [word for word in tokens if word.isalnum()]\n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    # Rejoin tokens into a single string\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing to the 'text' column\n",
    "df['cleaned_text'] = df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627965f4-b9f5-43da-aff1-f476cea557d8",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c039d460-55ef-4fb8-ba97-83c05601a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data into Training and Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_text'], df['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43ed748-e4cc-4fa3-8475-b7057d679b28",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e44b5c9-471a-41a1-a1c9-4ebbd9999136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289a735b-9655-4419-afa1-65f3fb63262c",
   "metadata": {},
   "source": [
    "## ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934e470d-95b3-49a2-b16d-3e62852dc25d",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression\n",
    "Logistic Regression is a linear model used for binary classification tasks. It estimates the probability that a given input belongs to a particular class. The logistic function (sigmoid) is used to map predicted values to probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44a26036-70c7-40c4-a445-2a24ffba1481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report ( Logistic Regression):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      4650\n",
      "           1       0.98      0.99      0.99      4330\n",
      "\n",
      "    accuracy                           0.99      8980\n",
      "   macro avg       0.99      0.99      0.99      8980\n",
      "weighted avg       0.99      0.99      0.99      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Logistic Regression model\n",
    "logistic_regression = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "logistic_regression.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_lr = logistic_regression.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report ( Logistic Regression):\")\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f68e49f-62c9-49fb-bd7c-141a9088da16",
   "metadata": {},
   "source": [
    "### 2. Multinomial Naive Bayes\n",
    "Multinomial Naive Bayes is a probabilistic algorithm based on Bayes' theorem. It assumes independence among features and is particularly effective for text classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64634745-b7a7-4594-ab0e-d24c4c261ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (Naive Bayes):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94      4650\n",
      "           1       0.93      0.93      0.93      4330\n",
      "\n",
      "    accuracy                           0.93      8980\n",
      "   macro avg       0.93      0.93      0.93      8980\n",
      "weighted avg       0.93      0.93      0.93      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "ml_model = MultinomialNB()\n",
    "\n",
    "# Train the model\n",
    "ml_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = ml_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report (Naive Bayes):\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151787d2-fe80-491f-a885-89082da99806",
   "metadata": {},
   "source": [
    "### 3. Support Vector Machines (SVM)\n",
    "SVM is a powerful classification algorithm that finds the hyperplane that best separates the classes in the feature space. It is effective in high-dimensional spaces and for cases where the number of dimensions exceeds the number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5d1b96e-9fb4-4bba-9fcf-42b72affc163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (SVM):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      4650\n",
      "           1       0.99      1.00      0.99      4330\n",
      "\n",
      "    accuracy                           0.99      8980\n",
      "   macro avg       0.99      0.99      0.99      8980\n",
      "weighted avg       0.99      0.99      0.99      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "svm_model = SVC(kernel='linear')\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report (SVM):\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d837cf0a-14c8-4fc7-95c6-e223615a799f",
   "metadata": {},
   "source": [
    "### 4. Random Forest Classifier\n",
    "Random Forest is an ensemble learning method that constructs multiple decision trees and merges them to get a more accurate and stable prediction. It handles overfitting well and provides a good balance between bias and variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de4dd1dc-2b40-4c76-9990-a2ddedb1805d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (Random Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      4650\n",
      "           1       0.99      0.99      0.99      4330\n",
      "\n",
      "    accuracy                           0.99      8980\n",
      "   macro avg       0.99      0.99      0.99      8980\n",
      "weighted avg       0.99      0.99      0.99      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rf_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report (Random Forest):\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b7569b-6459-4727-ab93-42ad86736b1f",
   "metadata": {},
   "source": [
    "### 5. Gradient Boosting Classifier\n",
    "Gradient Boosting is an ensemble technique that builds models sequentially, each trying to correct the errors of the previous one. It combines weak learners to create a strong learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7413e5f4-5970-47d9-8568-055ea23f0ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (Gradient Boosting):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      4650\n",
      "           1       0.99      1.00      0.99      4330\n",
      "\n",
      "    accuracy                           0.99      8980\n",
      "   macro avg       0.99      0.99      0.99      8980\n",
      "weighted avg       0.99      0.99      0.99      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "gb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = gb_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report (Gradient Boosting):\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c421fbb-3ce6-4236-a5ac-ef6bcac3820b",
   "metadata": {},
   "source": [
    "## Tokenization and Padding\n",
    "First, we need to tokenize the text data and then pad the sequences so they all have the same length. We'll use Tokenizer from Keras for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae1a584a-0048-412e-9be7-d4641301a456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "max_features = 10000  # Vocabulary size\n",
    "max_len = 200         # Maximum length of sequences\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "\n",
    "# Fit the tokenizer on the training data\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert text to sequences\n",
    "X_train_tokenized = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_tokenized = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad sequences to the same length\n",
    "X_train_pad = pad_sequences(X_train_tokenized, maxlen=max_len)\n",
    "X_test_pad = pad_sequences(X_test_tokenized, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a44e1b6-011f-40ad-9544-478d916f6a61",
   "metadata": {},
   "source": [
    "## Deep Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bca183-a9d5-40b6-b7c8-674542b8e23c",
   "metadata": {},
   "source": [
    "### 1. Deep Neural Network (DNN)\n",
    "DNNs are multi-layer neural networks that can model complex relationships in the data. They consist of input, hidden, and output layers, with each layer containing multiple neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f7e6297-e82b-4280-a598-843f2acd745b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 53ms/step - accuracy: 0.8949 - loss: 0.2276 - val_accuracy: 0.9829 - val_loss: 0.0464\n",
      "Epoch 2/5\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 49ms/step - accuracy: 0.9987 - loss: 0.0058 - val_accuracy: 0.9894 - val_loss: 0.0354\n",
      "Epoch 3/5\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 54ms/step - accuracy: 0.9999 - loss: 0.0010 - val_accuracy: 0.9882 - val_loss: 0.0411\n",
      "Epoch 4/5\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 8.8648e-04 - val_accuracy: 0.9878 - val_loss: 0.0439\n",
      "Epoch 5/5\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 64ms/step - accuracy: 0.9999 - loss: 7.7886e-04 - val_accuracy: 0.9878 - val_loss: 0.0474\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9881 - loss: 0.0451\n",
      "Loss: 0.04560296982526779, Accuracy: 0.9888641238212585\n"
     ]
    }
   ],
   "source": [
    "# Define model architecture\n",
    "dnn_model = Sequential([\n",
    "    Embedding(input_dim=max_features, output_dim=128, input_length=max_len),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "dnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = dnn_model.fit(X_train_pad, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = dnn_model.evaluate(X_test_pad, y_test)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7c444d-8e00-4353-839f-86ce5902f79d",
   "metadata": {},
   "source": [
    "### 2. Long Short-Term Memory (LSTM)\n",
    "LSTM is a type of recurrent neural network (RNN) capable of learning long-term dependencies. It is well-suited for sequence classification tasks like text classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df5caee2-dfdc-420f-abb6-7fed5f5725f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 522ms/step - accuracy: 0.8975 - loss: 0.2506 - val_accuracy: 0.9738 - val_loss: 0.0766\n",
      "Epoch 2/5\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 503ms/step - accuracy: 0.9855 - loss: 0.0490 - val_accuracy: 0.9844 - val_loss: 0.0573\n",
      "Epoch 3/5\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 536ms/step - accuracy: 0.9864 - loss: 0.0431 - val_accuracy: 0.9897 - val_loss: 0.0353\n",
      "Epoch 4/5\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 552ms/step - accuracy: 0.9939 - loss: 0.0188 - val_accuracy: 0.9747 - val_loss: 0.0743\n",
      "Epoch 5/5\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 527ms/step - accuracy: 0.9924 - loss: 0.0264 - val_accuracy: 0.9893 - val_loss: 0.0385\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 97ms/step - accuracy: 0.9872 - loss: 0.0412\n",
      "Loss: 0.0416342057287693, Accuracy: 0.9877505302429199\n"
     ]
    }
   ],
   "source": [
    "# Define model architecture\n",
    "lstm_model = Sequential([\n",
    "    Embedding(input_dim=max_features, output_dim=128, input_length=max_len),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    LSTM(64),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = lstm_model.fit(X_train_pad, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = lstm_model.evaluate(X_test_pad, y_test)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e1848a-5eaa-4a15-b96e-2faa09da6f67",
   "metadata": {},
   "source": [
    "### 3. Bidirectional LSTM\n",
    "Bidirectional LSTM (BiLSTM) captures information from both past and future states, making it more effective for sequence classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a969e877-a250-45e3-a0d7-276ea7e5fcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 653ms/step - accuracy: 0.8973 - loss: 0.2408 - val_accuracy: 0.9749 - val_loss: 0.0718\n",
      "Epoch 2/5\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 625ms/step - accuracy: 0.9818 - loss: 0.0565 - val_accuracy: 0.9823 - val_loss: 0.0596\n",
      "Epoch 3/5\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 598ms/step - accuracy: 0.9865 - loss: 0.0410 - val_accuracy: 0.9859 - val_loss: 0.0420\n",
      "Epoch 4/5\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 680ms/step - accuracy: 0.9943 - loss: 0.0161 - val_accuracy: 0.9811 - val_loss: 0.0494\n",
      "Epoch 5/5\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 697ms/step - accuracy: 0.9984 - loss: 0.0065 - val_accuracy: 0.9900 - val_loss: 0.0322\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 93ms/step - accuracy: 0.9871 - loss: 0.0399\n",
      "Loss: 0.03403124213218689, Accuracy: 0.988418698310852\n"
     ]
    }
   ],
   "source": [
    "# Define model architecture\n",
    "bi_lstm_model = Sequential([\n",
    "    Embedding(input_dim=max_features, output_dim=128, input_length=max_len),\n",
    "    Bidirectional(LSTM(128)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "bi_lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = bi_lstm_model.fit(X_train_pad, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = bi_lstm_model.evaluate(X_test_pad, y_test)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d482e63-491d-4598-b9c5-4f9420647577",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7578ffa9-6cda-47e9-b45e-a3709470c636",
   "metadata": {},
   "source": [
    "### Best ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa8ba2a-f2b2-4e6a-8bde-8461174b0f0b",
   "metadata": {},
   "source": [
    "As all the ML models that we have built, other than Multinomial Naive Bayes, are providing the same accuracy and other metrics like precision, recall, and F1-score, I have chosen the Random Forest Classifier for the following reasons:\n",
    "\n",
    "**Random Forest Classifier**\n",
    "\n",
    "Random Forest is an ensemble learning method that constructs multiple decision trees during training and outputs the mode of the classes (classification) of the individual trees. The idea behind Random Forest is to create a 'forest' of trees, each trained on a random subset of data and features, and then combine their predictions to improve accuracy and control overfitting.\n",
    "\n",
    "**Advantages of Random Forest:**\n",
    "\n",
    "Reduced Overfitting: By averaging the predictions of multiple trees, Random Forest reduces the risk of overfitting, which is a common problem in decision trees.\n",
    "\n",
    "Versatility: It can handle both classification and regression tasks and works well with high-dimensional data.\n",
    "\n",
    "Feature Importance: Provides insights into feature importance, aiding in feature selection and understanding the model.\n",
    "\n",
    "**Performance Metrics:**\n",
    "\n",
    "Accuracy: Random Forest achieved an accuracy of 99%, which is on par with other models but with additional benefits of robustness and interpretability.\n",
    "\n",
    "Precision, Recall, F1-Score: These metrics were equally high, indicating that Random Forest performs well in identifying both true positives and negatives.\n",
    "\n",
    "**Why Choose Random Forest Classifier?**\n",
    "\n",
    "Interpretability:\n",
    "\n",
    "Feature Importance: Random Forest provides feature importance scores, which help in understanding the influence of each feature on the predictions.\n",
    "Partial Dependence Plots: These plots can show the effect of a single feature on the target prediction, making the model somewhat interpretable.\n",
    "\n",
    "Robustness:\n",
    "\n",
    "Handling Overfitting: Random Forest reduces the risk of overfitting by averaging the results of multiple decision trees, which makes it more robust compared to single models.\n",
    "Handling Missing Values: Random Forest can handle missing values naturally by splitting on other features.\n",
    "\n",
    "Performance:\n",
    "\n",
    "Non-linear Relationships: Random Forest can capture non-linear relationships between features and the target variable, often leading to better performance compared to linear models.\n",
    "High Accuracy: Random Forest tends to achieve high accuracy, especially with well-tuned hyperparameters.\n",
    "\n",
    "Efficiency:\n",
    "\n",
    "Training Time: While slower than Logistic Regression, Random Forest is relatively faster than Gradient Boosting algorithms, making it a good compromise.\n",
    "Parallel Processing: Random Forest can be parallelized, leveraging multi-core processors for faster training and prediction.\n",
    "\n",
    "Scalability:\n",
    "\n",
    "Large Datasets: Random Forest can handle large datasets efficiently, making it suitable for your project.\n",
    "\n",
    "**Result**\n",
    "\n",
    "Choosing the Random Forest Classifier is a balanced decision considering the high accuracy, interpretability, and robustness. It provides a good trade-off between performance and usability, making it suitable for the fake news detection project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaed7a0-2538-4ac0-9678-49c2413bb714",
   "metadata": {},
   "source": [
    "### Best DL Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf33cd9d-8225-4d38-a34b-9bf068226f2f",
   "metadata": {},
   "source": [
    "As all the deep learning models that we have built are providing similar accuracy and other metrics, I have chosen the Bidirectional LSTM for the following reasons:\n",
    "\n",
    "**Bidirectional LSTM**\n",
    "\n",
    "Bidirectional Long Short-Term Memory (LSTM) is an advanced version of the traditional LSTM model, which processes data in both forward and backward directions. This helps in capturing contextual information from both the past and the future, leading to a better understanding of the sequence.\n",
    "\n",
    "**Advantages of Bidirectional LSTM:**\n",
    "\n",
    "Contextual Understanding:\n",
    "\n",
    "Bidirectional Processing: It captures dependencies from both directions, which is beneficial for text data where context is crucial.\n",
    "\n",
    "Improved Performance:\n",
    "\n",
    "Lower Loss: The Bidirectional LSTM achieved the lowest loss among the models, indicating better fit and potentially better generalization to unseen data.\n",
    "\n",
    "High Accuracy: It achieved high accuracy (98.84%), which is competitive with the other models.\n",
    "\n",
    "Handling Sequential Data:\n",
    "\n",
    "Complex Patterns: It captures complex sequential patterns, making it ideal for tasks involving text data.\n",
    "\n",
    "Performance Metrics:\n",
    "\n",
    "Accuracy: The Bidirectional LSTM achieved an accuracy of 98.84%, which is competitive with the other models but with a better loss value.\n",
    "\n",
    "Loss: The model achieved the lowest loss (0.0340), indicating a better fit to the data.\n",
    "\n",
    "**Why Choose Bidirectional LSTM?**\n",
    "\n",
    "Contextual Awareness:\n",
    "\n",
    "Forward and Backward Processing: The bidirectional nature of the model allows it to understand the context better, which is crucial for fake news detection.\n",
    "\n",
    "Performance Metrics:\n",
    "\n",
    "Lower Loss and High Accuracy: The combination of high accuracy and low loss makes it a robust choice for the task.\n",
    "\n",
    "Handling Sequential Data:\n",
    "\n",
    "Capturing Dependencies: It captures sequential dependencies better than a unidirectional LSTM, leading to improved performance in NLP tasks.\n",
    "\n",
    "**Result**\n",
    "\n",
    "Choosing the Bidirectional LSTM model is a balanced decision considering its ability to understand complex sequential data, high accuracy, and lower loss. It provides a robust and comprehensive solution for the fake news detection project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9cbe74-81b8-49f6-a1c7-58398e727cca",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847a9aaf-c19d-48e0-8cd1-83995e05c5bd",
   "metadata": {},
   "source": [
    "This project demonstrates the effectiveness of using machine learning and deep learning models for fake news classification. Both the Random Forest Classifier and Bidirectional LSTM showed promising results. Future work could explore the integration of more sophisticated NLP techniques and the use of larger datasets to further improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ccd893-e8d7-40bb-9071-1be53d1d91bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
